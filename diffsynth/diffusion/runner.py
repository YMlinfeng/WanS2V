import os, torch
from tqdm import tqdm
from accelerate import Accelerator
from .training_module import DiffusionTrainingModule
from .logger import ModelLogger
import torch
from tqdm import tqdm
import time
import time
from contextlib import contextmanager
from collections import defaultdict

class StepTimer:
    def __init__(self):
        self.times = defaultdict(list)
    
    @contextmanager
    def time_step(self, name):
        start = time.perf_counter()
        yield
        elapsed = time.perf_counter() - start
        self.times[name].append(elapsed)
    
    def print_summary(self):
        print("\n" + "="*60)
        print("è®¡æ—¶ç»Ÿè®¡æ‘˜è¦")
        print("="*60)
        for name, times in self.times.items():
            avg = sum(times) / len(times)
            total = sum(times)
            print(f"{name:25s}: å¹³å‡ {avg*1000:8.2f}ms | æ€»è®¡ {total:8.2f}s | æ¬¡æ•° {len(times)}")
        print("="*60)

def diagnose_default_training_status(model):
    """
    è¯Šæ–­æ¨¡å‹å½“å‰çš„é»˜è®¤è®­ç»ƒçŠ¶æ€ï¼ˆåœ¨äººå·¥ä¿®æ”¹ requires_grad ä¹‹å‰ï¼‰
    """
    print("\n" + "="*50)
    print("ğŸ•µï¸ [è¯Šæ–­æ¨¡å¼] æ£€æŸ¥æ¨¡å‹é»˜è®¤è®­ç»ƒçŠ¶æ€...")
    print("="*50)
    
    trainable_params = []
    frozen_params = []
    
    trainable_numel = 0
    frozen_numel = 0
    
    for name, param in model.named_parameters():
        if param.requires_grad:
            trainable_params.append(name)
            trainable_numel += param.numel()
        else:
            frozen_params.append(name)
            frozen_numel += param.numel()
            
    # ç»Ÿè®¡æ•°æ®
    total_layers = len(trainable_params) + len(frozen_params)
    total_params = trainable_numel + frozen_numel
    
    print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"   - æ€»å±‚æ•° (Keys): {total_layers}")
    print(f"   - æ€»å‚æ•°é‡ (Elements): {total_params / 1e9:.2f} B (åäº¿)")
    print(f"   -------------------------------------------")
    print(f"   ğŸ”“ å¯è®­ç»ƒå±‚æ•° (Trainable): {len(trainable_params)}")
    print(f"      - å‚æ•°é‡: {trainable_numel / 1e9:.2f} B")
    print(f"      - å æ¯”: {trainable_numel / total_params * 100:.2f}%")
    print(f"   ğŸ”’ ä¸å¯è®­ç»ƒå±‚æ•° (Frozen): {len(frozen_params)}")
    print(f"      - å‚æ•°é‡: {frozen_numel / 1e9:.2f} B")
    print(f"   -------------------------------------------")
    
    # æ‰“å°å…·ä½“åå­—ï¼ˆä¸ºäº†é˜²æ­¢åˆ·å±ï¼Œæ¯ç§åªæ‰“å°å‰5ä¸ªå’Œå5ä¸ªï¼‰
    if len(trainable_params) > 0:
        print(f"\nğŸ“ å¯è®­ç»ƒå‚æ•°ç¤ºä¾‹ (Top 5):")
        for p in trainable_params[:10]:
            print(f"   - [âˆš] {p}")
        if len(trainable_params) > 10: print("   ... (ä¸­é—´çœç•¥) ...")
        # æ‰“å°æœ€åå‡ ä¸ªï¼Œçœ‹çœ‹éŸ³é¢‘éƒ¨åˆ†åœ¨ä¸åœ¨
        for p in trainable_params[-10:]:
            print(f"   - [âˆš] {p}")
            
    if len(frozen_params) > 0:
        print(f"\nğŸ§Š ä¸å¯è®­ç»ƒå‚æ•°ç¤ºä¾‹ (Top 5):")
        for p in frozen_params[:10]:
            print(f"   - [x] {p}")
            
    print("="*50 + "\n")


def prepare_model_and_optimizer_groups(model, base_lr=1e-5, target_lr=1e-4):
    print("\n" + "="*50)
    print("ğŸ› ï¸  æ­£åœ¨é…ç½®æ¨¡å‹å‚æ•°ã€åˆå§‹åŒ–åŠå­¦ä¹ ç‡åˆ†ç»„...")
    print("="*50)

    # 1. å®šä¹‰é«˜å­¦ä¹ ç‡ï¼ˆä¸”éœ€è¦ç½®é›¶ï¼‰çš„ç›®æ ‡æ¨¡å—å‰ç¼€
    target_prefixes = (
        "audio_injector", 
        # "trainable_cond_mask", 
        # "frame_packer"
    )
    
    # 2. å®¹å™¨åˆå§‹åŒ–
    high_lr_params = []
    low_lr_params = []
    
    # ç»Ÿè®¡ç”¨å˜é‡
    stats = {
        "high_lr_count": 0,    # é«˜å­¦ä¹ ç‡å‚æ•°ä¸ªæ•°
        "low_lr_count": 0,     # ä½å­¦ä¹ ç‡å‚æ•°ä¸ªæ•° (Backboneä¸­åŸæœ¬å¯è®­ç»ƒçš„)
        "frozen_skipped": 0,   # è¢«è·³è¿‡çš„å†»ç»“å‚æ•° (å¦‚ TextEncoder)
        "zero_value_count": 0, # å®é™…å€¼ä¸º0çš„å‚æ•°ä¸ªæ•°
        "total_params": 0
    }

    # 3. éå†æ¨¡å‹æ‰€æœ‰å‚æ•°
    for name, param in model.named_parameters():
        stats["total_params"] += 1
        
        # åˆ¤æ–­æ˜¯å¦å±äºç›®æ ‡æ¨¡å— (Audio/Mask/Packer)
        is_target_module = any(prefix in name for prefix in target_prefixes)
        
        if is_target_module:
            # ============================================
            # A. ç›®æ ‡æ¨¡å—ï¼šå¼ºåˆ¶è®­ç»ƒ + å¼ºåˆ¶ç½®é›¶ + é«˜å­¦ä¹ ç‡
            # ============================================
            param.requires_grad = True # ç¡®ä¿å¼€å¯
            
            # æ‰§è¡Œå…¨é‡ç½®é›¶ (æ¢å¤ä½ ä¹‹å‰çš„é€»è¾‘)
            # with torch.no_grad():
            #     param.zero_()
            
            high_lr_params.append(param)
            stats["high_lr_count"] += 1
            
            # éªŒè¯ç½®é›¶
            if param.sum() == 0:
                stats["zero_value_count"] += 1
                
        else:
            # ============================================
            # B. éç›®æ ‡æ¨¡å—ï¼šå°Šé‡åŸçŠ¶æ€ (åªæ”¶å½•æœ¬æ¥å°±å¼€äº†æ¢¯åº¦çš„)
            # ============================================
            if param.requires_grad:
                # åŸæœ¬å°±æ˜¯å¯è®­ç»ƒçš„ (æ¯”å¦‚ Backbone çš„ Attention) -> ä½å­¦ä¹ ç‡
                low_lr_params.append(param)
                stats["low_lr_count"] += 1
            else:
                # åŸæœ¬å°±æ˜¯å†»ç»“çš„ (æ¯”å¦‚ Text Encoder) -> è·³è¿‡ï¼Œä¸è¿›ä¼˜åŒ–å™¨
                stats["frozen_skipped"] += 1

    # 4. æ‰“å°è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
    print(f"\nğŸ“Š å‚æ•°ç»Ÿè®¡æŠ¥å‘Š:")
    print(f"   -------------------------------------------")
    print(f"   [Total] æ¨¡å‹æ€»å‚æ•°å±‚æ•°: {stats['total_params']}")
    print(f"   -------------------------------------------")
    print(f"   ğŸ”¥ [High LR Group] (Target Modules, lr={target_lr})")
    print(f"       - åŒ…å«: {target_prefixes}")
    print(f"       - æ•°é‡: {stats['high_lr_count']}")
    print(f"       - ç½®é›¶éªŒè¯: {stats['zero_value_count']} / {stats['high_lr_count']} (åº”ç›¸ç­‰)")
    
    print(f"   â„ï¸ [Low LR Group] (Backbone SFT, lr={base_lr})")
    print(f"       - æ•°é‡: {stats['low_lr_count']}")
    print(f"       - è¯´æ˜: è¿™äº›æ˜¯SFTæƒé‡ä¸­åŸæœ¬å¼€å¯æ¢¯åº¦çš„éƒ¨åˆ†")
    
    print(f"   ğŸ§Š [Skipped/Frozen] (Not Training)")
    print(f"       - æ•°é‡: {stats['frozen_skipped']}")
    print(f"       - è¯´æ˜: è¿™äº›å‚æ•°ä¿æŒå†»ç»“ï¼Œä¸æ¶ˆè€—æ˜¾å­˜å­˜æ¢¯åº¦ (å¦‚TextEncoder)")
    print(f"   -------------------------------------------")

    # 5. æ„å»ºä¼˜åŒ–å™¨æ‰€éœ€çš„å‚æ•°ç»„åˆ—è¡¨
    optimizer_grouped_parameters = [
        {
            "params": low_lr_params, 
            "lr": base_lr,
            "name": "backbone_low_lr"
        },
        {
            "params": high_lr_params, 
            "lr": target_lr,
            "name": "audio_new_high_lr"
        }
    ]
    
    return optimizer_grouped_parameters

def launch_training_task(
    accelerator: Accelerator,
    dataset: torch.utils.data.Dataset,
    model: DiffusionTrainingModule,
    model_logger: ModelLogger,
    learning_rate: float = 1e-5,
    weight_decay: float = 1e-2,
    num_workers: int = 1,
    save_steps: int = None,
    num_epochs: int = 1,
    args = None,
):
    if args is not None:
        # small_lr_rate = 1e-5
        learning_rate = args.learning_rate
        weight_decay = args.weight_decay
        num_workers = args.dataset_num_workers
        save_steps = args.save_steps
        num_epochs = args.num_epochs
        debug = args.debug
    
    diagnose_default_training_status(model)
    # optimizer = torch.optim.AdamW(model.trainable_modules(), lr=learning_rate, weight_decay=weight_decay)
    optimizer_grouped_parameters = prepare_model_and_optimizer_groups(
        model, 
        base_lr=1e-5, 
        target_lr=learning_rate
    )
    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, weight_decay=weight_decay)
    scheduler = torch.optim.lr_scheduler.ConstantLR(optimizer)
    dataloader = torch.utils.data.DataLoader(dataset, shuffle=False, collate_fn=lambda x: x[0], num_workers=num_workers) if debug else torch.utils.data.DataLoader(dataset, shuffle=True, collate_fn=lambda x: x[0], num_workers=num_workers)
    
    model, optimizer, dataloader, scheduler = accelerator.prepare(model, optimizer, dataloader, scheduler)
    
    # model_logger.on_training_start(accelerator, model)
    
    # for epoch_id in range(num_epochs):
    #     for data in tqdm(dataloader):
    #         with accelerator.accumulate(model):
    #             optimizer.zero_grad()
    #             loss = model(data)
    #             accelerator.backward(loss)
    #             optimizer.step()
    #             model_logger.on_step_end(accelerator, model, save_steps)
    #             scheduler.step() # è¿™ä¸€æ­¥ä¸ºä»€ä¹ˆè¿™ä¹ˆæ…¢
    # model_logger.on_training_end(accelerator, model, save_steps)

    timer = StepTimer()

    for epoch_id in range(num_epochs):
        # for data in tqdm(dataloader):
        for step_index, data in enumerate(tqdm(dataloader, desc=f"Epoch {epoch_id}")):
            with accelerator.accumulate(model):
                
                with timer.time_step("zero_grad"):
                    optimizer.zero_grad()
                
                with timer.time_step("forward"):
                    loss = model(data)
                
                with timer.time_step("backward"):
                    accelerator.backward(loss)
                
                with timer.time_step("optimizer.step"):
                    optimizer.step()
                
                with timer.time_step("model_logger"):
                    model_logger.on_step_end(accelerator, model, save_steps)
                
                with timer.time_step("scheduler.step"):
                    scheduler.step()

    model_logger.on_training_end(accelerator, model, save_steps)

    # æ‰“å°ç»Ÿè®¡ç»“æœ
    timer.print_summary()



def launch_data_process_task(
    accelerator: Accelerator,
    dataset: torch.utils.data.Dataset,
    model: DiffusionTrainingModule,
    model_logger: ModelLogger,
    num_workers: int = 8,
    args = None,
):
    if args is not None:
        num_workers = args.dataset_num_workers
        
    dataloader = torch.utils.data.DataLoader(dataset, shuffle=False, collate_fn=lambda x: x[0], num_workers=num_workers)
    model, dataloader = accelerator.prepare(model, dataloader)
    
    for data_id, data in enumerate(tqdm(dataloader)):
        with accelerator.accumulate(model):
            with torch.no_grad():
                folder = os.path.join(model_logger.output_path, str(accelerator.process_index))
                os.makedirs(folder, exist_ok=True)
                save_path = os.path.join(model_logger.output_path, str(accelerator.process_index), f"{data_id}.pth")
                data = model(data)
                torch.save(data, save_path)
